{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv('train_values.csv', dtype= {'building_id': np.int32,\\\n",
    "                                              'geo_level_1_id': np.int8,\\\n",
    "                                              'geo_level_2_id': np.int16,\\\n",
    "                                              'geo_level_3_id': np.int16,\\\n",
    "                                              'count_floors_pre_eq': np.int16,\\\n",
    "                                              'age': np.int16,\\\n",
    "                                              'area_percentage': np.int8,\\\n",
    "                                              'height_percentage': np.int8,\\\n",
    "                                              'land_surface_condition': 'category',\\\n",
    "                                              'foundation_type': 'category',\\\n",
    "                                              'roof_type': 'category',\\\n",
    "                                              'ground_floor_type':'category',\\\n",
    "                                              'other_floor_type': 'category',\\\n",
    "                                              'position': 'category',\\\n",
    "                                              'plan_configuration':'category',\\\n",
    "                                              'has_superstructure_adobe_mud':'boolean',\\\n",
    "                                              'has_superstructure_mud_mortar_stone':'boolean',\\\n",
    "                                              'has_superstructure_stone_flag':'boolean',\\\n",
    "                                              'has_superstructure_cement_mortar_stone':'boolean',\\\n",
    "                                              'has_superstructure_mud_mortar_brick':'boolean',\\\n",
    "                                              'has_superstructure_cement_mortar_brick':'boolean',\\\n",
    "                                              'has_superstructure_timber':'boolean',\\\n",
    "                                              'has_superstructure_bamboo':'boolean',\\\n",
    "                                              'has_superstructure_rc_non_engineered':'boolean',\\\n",
    "                                              'has_superstructure_rc_engineered':'boolean',\\\n",
    "                                              'has_superstructure_other':'boolean',\\\n",
    "                                              'legal_ownership_status':'category',\\\n",
    "                                              'count_families': np.int16,\\\n",
    "                                              'has_secondary_use':'boolean',\\\n",
    "                                              'has_secondary_use_agriculture':'boolean',\\\n",
    "                                              'has_secondary_use_hotel':'boolean',\\\n",
    "                                              'has_secondary_use_rental':'boolean',\\\n",
    "                                              'has_secondary_use_institution':'boolean',\\\n",
    "                                              'has_secondary_use_school':'boolean',\\\n",
    "                                              'has_secondary_use_industry':'boolean',\\\n",
    "                                              'has_secondary_use_health_post':'boolean',\\\n",
    "                                              'has_secondary_use_gov_office':'boolean',\\\n",
    "                                              'has_secondary_use_use_police':'boolean',\\\n",
    "                                              'has_secondary_use_other':'boolean'\n",
    "                                              })\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_values = pd.read_csv(\"test_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pre = pd.get_dummies(train_values).set_index('building_id')\n",
    "y_pre = train_labels.loc[:,'damage_grade']\n",
    "\n",
    "x = x_pre\n",
    "y = y_pre\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper = {\"hidden_layer_sizes\" : [10,20,30,40,50,100,200,500,1000], \n",
    "         \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "        \"solver\": [\"lbfgs\",\"sgd\",\"adam\"],\n",
    "        \"learning_rate\":['constant', \"invscaling\", \"adaptive\"],\n",
    "        }\n",
    "nn_mlp = MLPClassifier()\n",
    "rn_sr = RandomizedSearchCV(nn_mlp,param_distributions = hiper, scoring = 'f1_micro',cv=5,n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'activation': ['identity', 'logistic',\n",
       "                                                       'tanh', 'relu'],\n",
       "                                        'hidden_layer_sizes': [10, 20, 30, 40,\n",
       "                                                               50, 100, 200,\n",
       "                                                               500, 1000],\n",
       "                                        'learning_rate': ['constant',\n",
       "                                                          'invscaling',\n",
       "                                                          'adaptive'],\n",
       "                                        'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "                   scoring='f1_micro')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn_sr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5698244435917115\n",
      "{'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': 40, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(rn_sr.best_score_)\n",
    "bst_parms = rn_sr.best_params_\n",
    "print(bst_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.569392747505756\n",
      "Test Score: 0.5682738243702155\n"
     ]
    }
   ],
   "source": [
    "mlp_class = MLPClassifier(hidden_layer_sizes = bst_parms[\"hidden_layer_sizes\"],\n",
    "                         activation = bst_parms[\"activation\"],\n",
    "                         solver = bst_parms[\"solver\"],\n",
    "                         learning_rate = bst_parms[\"learning_rate\"])\n",
    "model0 = mlp_class.fit(x_train, y_train)\n",
    "\n",
    "model0.predict(x_test)\n",
    "print(\"Training Score: {}\".format(mlp_class.score(x_train, y_train)))\n",
    "print(\"Test Score: {}\".format(mlp_class.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr = GridSearchCV(nn_mlp,param_grid = hiper, scoring = 'f1_micro',cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gd_sr.best_score_)\n",
    "bst_parms1 = gd_sr.best_params_\n",
    "print(bst_parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_class1 = MLPClassifier(hidden_layer_sizes = bst_parms1[\"hidden_layer_sizes\"],\n",
    "                         activation = bst_parms1[\"activation\"],\n",
    "                         solver = bst_parms1[\"solver\"],\n",
    "                         learning_rate = bst_parms1[\"learning_rate\"])\n",
    "model1 = mlp_class.fit(x_train, y_train)\n",
    "\n",
    "model1.predict(x_test)\n",
    "print(\"Training Score: {}\".format(mlp_class1.score(x_train, y_train)))\n",
    "print(\"Test Score: {}\".format(mlp_class1.score(x_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
